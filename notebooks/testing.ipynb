{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing heatmap labels generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join('..','src')) \n",
    "import network\n",
    "import utils\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "data_type = 'heatmap_crops'\n",
    "#data_type = 'region_crops'\n",
    "prediction_class_type = 'odm'\n",
    "#prediction_class_type = 'single'\n",
    "validate = True\n",
    "class_balancing = False\n",
    "input_shape = (224, 224, 3)\n",
    "mini_batch_size = 128\n",
    "crop_size = 400\n",
    "arch = 'xception'\n",
    "input_weights_name = 'xception-lay86-heatmap_crops-ep000-tloss0.0068-vloss0.0069.hdf5'\n",
    "tl = network.TransferLearningSeaLionHeatmap(data_type = data_type, input_shape = input_shape, prediction_class_type = prediction_class_type, class_balancing= class_balancing, mini_batch_size=mini_batch_size, validate = validate)\n",
    "#tl = network.TransferLearningSeaLionOrNoSeaLion(data_type = data_type, input_shape = input_shape, prediction_class_type = prediction_class_type, class_balancing= class_balancing, mini_batch_size=mini_batch_size, validate = validate)\n",
    "tl.build(arch, input_shape = input_shape)\n",
    "tl.load_weights(input_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = tl.val_iterator.__next__()\n",
    "print(y_batch.mean(), x_batch.mean())\n",
    "\n",
    "for i in range(mini_batch_size):   \n",
    "    x = x_batch[i]#\n",
    "    pred = tl.model.predict(np.expand_dims(x, axis = 0))[0].reshape((80, 80))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(x)\n",
    "    scipy.misc.imsave('delete/'+str(i)+'_x.jpg',x)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(pred, cmap = 'gray')\n",
    "    scipy.misc.imsave('delete/'+str(i)+'_pred.jpg', scipy.misc.imresize(pred.reshape((80, 80)), (224,224)))\n",
    "    plt.title(str(pred.mean()))\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y_batch[i].reshape((80, 80)), cmap = 'gray')\n",
    "    scipy.misc.imsave('delete/'+str(i)+'_ground.jpg', scipy.misc.imresize(y_batch[i].reshape((80, 80)), (224,224)))\n",
    "    plt.title(str(y_batch[i].reshape((80, 80)).mean()))\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test images heatmap predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2017-06-13 16:49:09,707 - noaa - INFO - Starting...\n",
      "2017-06-13 16:49:09,708 - noaa.data - DEBUG - Loading train image counts\n",
      "2017-06-13 16:49:09,720 - noaa.data - DEBUG - Loading train image coordinates\n",
      "2017-06-13 16:49:10,317 - noaa.data - DEBUG - Loading train image mismatch labels\n",
      "2017-06-13 16:49:10,321 - noaa - INFO - Resizing images deactivated\n",
      "2017-06-13 16:49:10,328 - noaa.data - DEBUG - Loading stage 1 test set original images\n",
      "2017-06-13 16:49:15,165 - noaa - INFO - Building network using xception as the pretrained architecture...\n",
      "../src/network.py:338: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "  self.model = keras.models.Model(input=self.base_model.input, output=predictions)\n",
      "2017-06-13 16:49:15,263 - noaa - INFO - Output shape of first layer is (None, 224, 224, 3)\n",
      "2017-06-13 16:49:15,264 - noaa - INFO - Output shape of last layer is (None, 80, 80, 1)\n",
      "2017-06-13 16:49:16,393 - noaa - INFO - Loaded weights /vol/tensusers/vgarciacazorla/MLP/noaa-sea-lion-count/data/weights/xception-lay86-heatmap_crops-ep000-tloss0.0068-vloss0.0069.hdf5\n",
      "2017-06-13 16:49:16,395 - noaa.data - DEBUG - Loading train image counts\n",
      "2017-06-13 16:49:16,405 - noaa.data - DEBUG - Loading train image coordinates\n",
      "2017-06-13 16:49:16,964 - noaa.data - DEBUG - Loading train image mismatch labels\n",
      "2017-06-13 16:49:16,966 - noaa.data - DEBUG - Loading stage 1 test set original images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join('..','src')) \n",
    "import network\n",
    "import utils\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import settings\n",
    "import data\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "data_type = 'original_test'\n",
    "#data_type = 'region_crops'\n",
    "prediction_class_type = 'odm'\n",
    "#prediction_class_type = 'single'\n",
    "validate = False\n",
    "class_balancing = False\n",
    "input_shape = (224, 224, 3)\n",
    "batch_size = 1\n",
    "crop_size = 400\n",
    "arch = 'xception'\n",
    "input_weights_name = 'xception-lay86-heatmap_crops-ep000-tloss0.0068-vloss0.0069.hdf5'\n",
    "tl = network.TransferLearningSeaLionHeatmap(data_type = data_type, input_shape = input_shape, prediction_class_type = prediction_class_type, class_balancing= class_balancing, mini_batch_size=batch_size, validate = validate)\n",
    "#tl = network.TransferLearningSeaLionOrNoSeaLion(data_type = data_type, input_shape = input_shape, prediction_class_type = prediction_class_type, class_balancing= class_balancing, mini_batch_size=mini_batch_size, validate = validate)\n",
    "tl.build(arch, input_shape = input_shape)\n",
    "tl.load_weights(input_weights_name)\n",
    "\n",
    "loader = data.Loader()\n",
    "test_data = loader.load_original_images(dataset = 'test_st1')\n",
    "iterator = data.DataIterator(test_data, data_transformation = data.LoadTransformer(), batch_size = batch_size, shuffle = False, seed = None, class_balancing = False, class_transformation = lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-13 16:52:42,048 - noaa - INFO - Going for image with shape (3840, 5760, 3)\n",
      "2017-06-13 16:52:42,051 - noaa - INFO - 0.0% completed\n",
      "2017-06-13 16:53:06,128 - noaa - INFO - 6.34% completed\n",
      "2017-06-13 16:53:36,982 - noaa - INFO - 12.6% completed\n",
      "2017-06-13 16:54:03,006 - noaa - INFO - 19.0% completed\n",
      "2017-06-13 16:54:23,357 - noaa - INFO - 25.3% completed\n",
      "2017-06-13 16:54:37,742 - noaa - INFO - 31.7% completed\n",
      "2017-06-13 16:54:51,987 - noaa - INFO - 38.0% completed\n",
      "2017-06-13 16:55:06,882 - noaa - INFO - 44.4% completed\n",
      "2017-06-13 16:55:16,974 - noaa - INFO - 50.7% completed\n",
      "2017-06-13 16:55:30,517 - noaa - INFO - 57.1% completed\n",
      "2017-06-13 16:55:42,335 - noaa - INFO - 63.4% completed\n",
      "2017-06-13 16:55:53,428 - noaa - INFO - 69.8% completed\n",
      "2017-06-13 16:56:07,056 - noaa - INFO - 76.1% completed\n",
      "2017-06-13 16:56:20,419 - noaa - INFO - 82.5% completed\n",
      "2017-06-13 16:56:35,407 - noaa - INFO - 88.8% completed\n",
      "2017-06-13 16:56:48,791 - noaa - INFO - 95.2% completed\n",
      "2017-06-13 16:57:23,696 - noaa - INFO - ... completed in 296.0149393081665 seconds\n",
      "2017-06-13 16:57:36,654 - noaa - INFO - Going for image with shape (3744, 5616, 3)\n",
      "2017-06-13 16:57:36,656 - noaa - INFO - 0.0% completed\n",
      "2017-06-13 16:57:49,067 - noaa - INFO - 6.34% completed\n",
      "2017-06-13 16:58:01,259 - noaa - INFO - 12.6% completed\n",
      "2017-06-13 16:58:16,488 - noaa - INFO - 19.0% completed\n",
      "2017-06-13 16:58:27,436 - noaa - INFO - 25.3% completed\n",
      "2017-06-13 16:58:43,024 - noaa - INFO - 31.7% completed\n",
      "2017-06-13 16:58:54,458 - noaa - INFO - 38.0% completed\n"
     ]
    }
   ],
   "source": [
    "for n in range(100):\n",
    "    t0 = time.time()\n",
    "    test_image = iterator.__next__()[0]\n",
    "    test_image = test_image / test_image.max()\n",
    "    #print(test_image.mean())\n",
    "    plot = False\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(test_image)\n",
    "        plt.show()\n",
    "    nrows = int(test_image.shape[0]/crop_size)\n",
    "    ncolumns = int(test_image.shape[1]/crop_size)\n",
    "    full_obm = []\n",
    "    settings.logger.info(\"Going for image with shape \"+str(test_image.shape))\n",
    "    total = float((nrows * ncolumns))\n",
    "    count = 0.0\n",
    "    for row in range(nrows):\n",
    "        row_obms = []\n",
    "        for column in range(ncolumns):\n",
    "            if count%8==0:\n",
    "                settings.logger.info(str(100*count/total)[:4]+\"% completed\")\n",
    "\n",
    "            crop = utils.crop_image(test_image, (column*crop_size, row*crop_size), crop_size)\n",
    "            crop = scipy.misc.imresize(crop, input_shape)\n",
    "            if crop.max() > 0:\n",
    "                crop = crop / crop.max()\n",
    "\n",
    "            crop = np.expand_dims(crop, axis = 0)\n",
    "\n",
    "            obm = tl.model.predict(crop)\n",
    "            obm = np.squeeze(obm)\n",
    "            row_obms.append(obm)\n",
    "            count += 1\n",
    "        row_obms = np.hstack(row_obms)\n",
    "        full_obm.append(row_obms)  \n",
    "\n",
    "    full_obm = np.vstack(full_obm)\n",
    "    #print(full_obm.shape, full_obm.max(),full_obm.mean(),full_obm.min())\n",
    "    if plot and 0:\n",
    "        plt.figure()\n",
    "        plt.imshow(np.squeeze(full_obm), cmap = 'gray')\n",
    "        plt.show()\n",
    "    trunc_img = test_image[:crop_size*nrows,:crop_size*ncolumns]\n",
    "    trunc_img = scipy.misc.imresize(trunc_img, (full_obm.shape[0],full_obm.shape[1],3))\n",
    "    trunc_img = trunc_img / trunc_img.max()\n",
    "    red_obm = np.zeros((full_obm.shape[0],full_obm.shape[1],3))\n",
    "    red_obm[:,:,0] = full_obm\n",
    "    red_obm = red_obm / red_obm.max()\n",
    "    img_sum = cv2.addWeighted(src1 = trunc_img, alpha = 1, src2 = red_obm, beta = 0.6, gamma = 0.001)\n",
    "    img_sum = img_sum / img_sum.max()\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.imshow(img_sum)\n",
    "        plt.show()\n",
    "    scipy.misc.imsave('delete/'+str(n)+'.jpg',img_sum)\n",
    "    settings.logger.info(\"... completed in \"+str(time.time()-t0)+\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join('..','src')) \n",
    "import network\n",
    "import utils\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from scipy.misc import imresize\n",
    "%matplotlib inline\n",
    "\n",
    "data_type = 'original_test'\n",
    "validate = False\n",
    "input_shape = (224, 224, 3)\n",
    "mini_batch_size = 1\n",
    "crop_size = 400\n",
    "arch = 'resnet'\n",
    "input_weights_name = 'resnet-lay107-ep002-tloss0.0134-vloss0.0166.hdf5'\n",
    "tl = network.TransferLearningSeaLionOrNoSeaLion(data_type = data_type, input_shape = input_shape, prediction_class_type = \"single\", mini_batch_size=mini_batch_size, validate = validate)\n",
    "tl.build(arch, input_shape = input_shape, summary = False)\n",
    "tl.load_weights(input_weights_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## load one test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image = tl.iterator.__next__()[0]\n",
    "plt.figure()\n",
    "plt.imshow(test_image)\n",
    "plt.title(str(test_image.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coordinates = [3330, 1100]\n",
    "step_px = 50\n",
    "samples = 20\n",
    "for i in range(samples):\n",
    "    crop = utils.crop_image(test_image, tuple(coordinates), crop_size)\n",
    "    crop = scipy.misc.imresize(crop,(224,224,3))\n",
    "    pred = tl.model.predict(crop.reshape((1,224,224,3)))[0][0]\n",
    "    plt.figure()\n",
    "    plt.imshow(crop)\n",
    "    plt.title(str(pred))\n",
    "    coordinates[1] = coordinates[1] + step_px\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(samples):\n",
    "    coordinates = (random.randint(0,test_image.shape[1]-crop_size), random.randint(0,test_image.shape[0]-crop_size))\n",
    "    crop = utils.crop_image(test_image, coordinates, crop_size)\n",
    "    crop = scipy.misc.imresize(crop,(224,224,3))\n",
    "    plt.figure()\n",
    "    plt.imshow(crop)\n",
    "    pred = tl.model.predict(crop.reshape((1,224,224,3)))[0][0]\n",
    "    plt.title(str(pred))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
